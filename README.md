# ğŸ“¡ TelcoRetentionAI

The complete project documentation was made with mkDocs and is available on the following official [TelcoRetention AI](https://tralencar.github.io/telco_retention_ai/).

**TelcoRetentionAI** is a machine learning project that predicts customer churn for a fictional telecom company using advanced analytics, model optimization, and explainability techniques. It provides interpretable predictions and business insights to help companies reduce churn and prioritize customer retention strategies.

---

## ğŸ” Project Summary

- **Name**: `telco_retention_ai`
- **Author**: `tralencar`
- **Version**: `0.1.0`
- **License**: `MIT`
- **Keywords**: `churn`, `telco`, `retention`, `AI`, `customer-lifetime-value`
- **Dataset Source**: [Kaggle - Telco Customer Churn](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)

---

## ğŸ§  Project Goals

### ğŸ¯ Primary Goal

Build a **binary classification model** to predict if a customer will cancel their service in the next billing cycle.

### ğŸ“Š Secondary Goal


Generate business insights and dashboards to highlight:

- Contract type, tech support, billing profile impact
- Demographic and behavioral churn patterns
- Actionable retention strategies for targeted segments

---

## ğŸ—ï¸ Project eatures

âœ… Programming Language: `Python`<br>
âœ… Hyperparameter optimization with `Optuna`<br>
âœ… Class balancing with `SMOTE` (`imblearn`)<br>
âœ… Evaluation using `scikit-learn` metrics<br>
âœ… Support for `Gradient Boosting`, `Random Forest`, and `Logistic Regression` models<br>
âœ… Code quality ensured by `Pre-commit`, `Ruff`, `Black`, `Flake8`, `Isort`, `Interrogate`<br>
âœ… Task automation with `Makefile`<br>
âœ… Semantic versioning using `bump2version`<br>
âœ… Automated testing with `Pytest` + `Pytest-Cov`<br>
âœ… Notebook linting and quality enforcement using `nbQA`<br>
âœ… Auto-generated documentation with `MkDocs`, `MkDocs Material`, and `mkdocstrings-python`<br>
âœ… Automatic formatting and linting with `Ruff`, `Black`, and `Isort`<br>
âœ… Enhanced documentation design with `mkdocs-bootstrap386` and `pymdown-extensions`<br>
âœ… Git hooks for code validation using `Pre-commit`<br>
âœ… Modular and reusable structure managed with `Poetry`<br>
âœ… **Continuous Integration (CI)** with `GitHub Actions`, including:<br>
ğŸ”¹ Code quality checks on every `push` or `pull request` to `main`<br>
ğŸ”¹ Automated setup of the `Python` environment with `Poetry`<br>
ğŸ”¹ Automatic installation of development dependencies<br>
ğŸ”¹ Execution of the `make quality` rule to enforce coding standards

---

## ğŸ§ª Development Tools

- `ruff` â€” Linting and formatting (line length = 88, flake8-bugbear, isort, pyflakes, pycodestyle)
- `black` â€” Code formatter
- `isort` â€” Import ordering
- `flake8` â€” Linting
- `interrogate` â€” Docstring coverage checker
- `pytest`, `pytest-cov` â€” Unit testing and coverage
- `pre-commit` â€” Git hooks for automated code checks
- `nbqa` â€” Jupyter Notebook quality checks
- `bump2version` â€” Semantic version control

---

## ğŸ”¹ Installing Dependencies

### **1ï¸âƒ£ Clone the repository**

```bash
git clone https://github.com/tralencar/telco_retention_ai.git
cd telco_retention_ai
```

### **2ï¸âƒ£ Install Poetry (if not installed)**

```bash
pip install poetry
```

### **3ï¸âƒ£ Set Poetry to create virtual environments inside the project folder**

```bash
poetry config virtualenvs.in-project true
```

ğŸ“Œ Note:

This will create the .venv/ folder inside the project for better isolation.

### **4ï¸âƒ£ Activate the virtual environment**

```bash
poetry shell
```

### **5ï¸âƒ£ Install all dependencies**

```bash
poetry install
```

### ğŸ”¹ Setting up Pre-commit

To ensure code quality on each commit, install the pre-commit hooks:

```bash
poetry run pre-commit install
```

ğŸ“Œ All hooks will run automatically before each commit.

### ğŸ”¹ Verifying Installation

Test your environment with:

```bash
poetry run python -c "import pandas; print('Installation successful!')"
```

---

## ğŸ”¹ ğŸ“ˆ CRISP-DM Methodology

This project follows the CRISP-DM methodology, structured in the following stages:

* Business Understanding
* Data Understanding
* Data Preparation
* Modeling
* Evaluation
* Deployment (recommendations & scoring)

## ğŸ”¹ ğŸ“Š Evaluation Highlights

* Best Model: Gradient Boosting
* AUC-ROC > 0.82
* Lift curve and calibration show excellent model stability

## ğŸ”¹ ğŸ’¡ Actionable Recommendations

* Offer loyalty plans to month-to-month customers
* Upsell Tech Support to reduce churn risk
* Target high-risk + high-CLTV users for retention campaigns
* Customize messaging for seniors, paperless billing users, and singles

## ğŸ”¹ ğŸ”— Acknowledgements

* Dataset: IBM Telco Customer Churn (Kaggle)

---
