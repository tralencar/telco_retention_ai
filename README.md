# ðŸ“¡ TelcoRetentionAI

The complete project documentation was made with mkDocs and is available on the following official [TelcoRetention AI](https://tralencar.github.io/telco_retention_ai/).

**TelcoRetentionAI** is a machine learning project that predicts customer churn for a fictional telecom company using advanced analytics, model optimization, and explainability techniques. It provides interpretable predictions and business insights to help companies reduce churn and prioritize customer retention strategies.

---

## ðŸ” Project Summary

- **Name**: `telco_retention_ai`
- **Author**: `tralencar`
- **Version**: `0.1.0`
- **License**: `MIT`
- **Keywords**: `churn`, `telco`, `retention`, `AI`, `customer-lifetime-value`
- **Dataset Source**: [Kaggle - Telco Customer Churn](https://www.kaggle.com/datasets/blastchar/telco-customer-churn)

---

## ðŸ§  Project Goals

### ðŸŽ¯ Primary Goal

Build a **binary classification model** to predict if a customer will cancel their service in the next billing cycle.

### ðŸ“Š Secondary Goal


Generate business insights and dashboards to highlight:

- Contract type, tech support, billing profile impact
- Demographic and behavioral churn patterns
- Actionable retention strategies for targeted segments

---

## ðŸ—ï¸ Project eatures

âœ… Programming Language: `Python`
âœ… Hyperparameter optimization with `Optuna`
âœ… Class balancing with `SMOTE` (`imblearn`)
âœ… Evaluation using `scikit-learn` metrics
âœ… Support for `Gradient Boosting`, `Random Forest`, and `Logistic Regression` models
âœ… Code quality ensured by `Pre-commit`, `Ruff`, `Black`, `Flake8`, `Isort`, `Interrogate`
âœ… Task automation with `Makefile`
âœ… Semantic versioning using `bump2version`
âœ… Automated testing with `Pytest` + `Pytest-Cov`
âœ… Notebook linting and quality enforcement using `nbQA`
âœ… Auto-generated documentation with `MkDocs`, `MkDocs Material`, and `mkdocstrings-python`
âœ… Automatic formatting and linting with `Ruff`, `Black`, and `Isort`
âœ… Enhanced documentation design with `mkdocs-bootstrap386` and `pymdown-extensions`
âœ… Git hooks for code validation using `Pre-commit`
âœ… Modular and reusable structure managed with `Poetry`
âœ… **Continuous Integration (CI)** with `GitHub Actions`, including:
ðŸ”¹ Code quality checks on every `push` or `pull request` to `main`
ðŸ”¹ Automated setup of the `Python` environment with `Poetry`
ðŸ”¹ Automatic installation of development dependencies
ðŸ”¹ Execution of the `make quality` rule to enforce coding standards

## ðŸ§ª Development Tools

- `ruff` â€” Linting and formatting (line length = 88, flake8-bugbear, isort, pyflakes, pycodestyle)
- `black` â€” Code formatter
- `isort` â€” Import ordering
- `flake8` â€” Linting
- `interrogate` â€” Docstring coverage checker
- `pytest`, `pytest-cov` â€” Unit testing and coverage
- `pre-commit` â€” Git hooks for automated code checks
- `nbqa` â€” Jupyter Notebook quality checks
- `bump2version` â€” Semantic version control

---

## ðŸ”¹ Installing Dependencies

### **1ï¸âƒ£ Clone the repository**

```bash
git clone https://github.com/tralencar/telco_retention_ai.git
cd telco_retention_ai
```

### **2ï¸âƒ£ Install Poetry (if not installed)**

```bash
pip install poetry
```

### **3ï¸âƒ£ Set Poetry to create virtual environments inside the project folder**

```bash
poetry config virtualenvs.in-project true
```

ðŸ“Œ Note:

This will create the .venv/ folder inside the project for better isolation.

### **4ï¸âƒ£ Activate the virtual environment**

```bash
poetry shell
```

### **5ï¸âƒ£ Install all dependencies**

```bash
poetry install
```

### ðŸ”¹ Setting up Pre-commit

To ensure code quality on each commit, install the pre-commit hooks:

```bash
poetry run pre-commit install
```

ðŸ“Œ All hooks will run automatically before each commit.

### ðŸ”¹ Verifying Installation

Test your environment with:

```bash
poetry run python -c "import pandas; print('Installation successful!')"
```

---

## ðŸ”¹ ðŸ“ˆ CRISP-DM Methodology

This project follows the CRISP-DM methodology, structured in the following stages:

* Business Understanding
* Data Understanding
* Data Preparation
* Modeling
* Evaluation
* Deployment (recommendations & scoring)

## ðŸ”¹ ðŸ“Š Evaluation Highlights

* Best Model: Gradient Boosting
* AUC-ROC > 0.82
* Lift curve and calibration show excellent model stability

## ðŸ”¹ ðŸ’¡ Actionable Recommendations

* Offer loyalty plans to month-to-month customers
* Upsell Tech Support to reduce churn risk
* Target high-risk + high-CLTV users for retention campaigns
* Customize messaging for seniors, paperless billing users, and singles

## ðŸ”¹ ðŸ”— Acknowledgements

* Dataset: IBM Telco Customer Churn (Kaggle)
